{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "HyperTone - Fit.ipynb",
      "provenance": [],
      "mount_file_id": "1RrnkabZVmWduNMQ_myL12ZCz2YJMc-Qi",
      "authorship_tag": "ABX9TyMHvFC4mtRSTSC2zMMCSL/4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stoianmihail/HyperTone/blob/main/HyperTone_Fit-Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTVG1bmuFKiE"
      },
      "source": [
        "# lstm model\n",
        "import numpy as np\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import dstack\n",
        "from pandas import read_csv\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import BatchNormalization as BatchNorm\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOOwoBDuGDDg"
      },
      "source": [
        "hypertone_dir = '/content/drive/MyDrive/hypertone/'\n",
        "model_dir = hypertone_dir + 'model/'\n",
        "model_file = hypertone_dir + 'model/model'\n",
        "preprocessing_dir = hypertone_dir + 'preprocessing/'"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXHHME_wGQyy"
      },
      "source": [
        "import os\n",
        "def get_files(path):\n",
        "  ret = []\n",
        "  for root, _, files in os.walk(path, topdown=False):\n",
        "    for file in files:\n",
        "      ret.append({'path': os.path.join(root,file), 'data' : None})\n",
        "  return ret"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZl4DC3qFfn-",
        "outputId": "ab2c725c-a88b-4e7c-aff1-4d83c55963c1"
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "def compress(a):\n",
        "  return a[np.logical_or(np.insert(np.diff(a).astype(bool), 0, True), np.asarray(a, dtype=bool))]\n",
        "\n",
        "def parse_songs():\n",
        "  songs = {}\n",
        "  for file in get_files(preprocessing_dir):\n",
        "    if '.pkl' not in file['path']:\n",
        "      continue \n",
        "    song_name = os.path.basename(file['path']).replace('.pkl', '')\n",
        "    x = pd.read_pickle(file['path'])\n",
        "    compressed = compress(np.asarray(x[1]))\n",
        "    compressed = compressed[compressed != 0]\n",
        "\n",
        "    # TODO: this is only for these recordings\n",
        "    # TODO: Next time, also save the label!\n",
        "    tone = int(x[2])\n",
        "    #if tone == 1 or tone == 8:# or tone == 5 or tone == 3:\n",
        "    songs[song_name] = {'x': compressed, 'y': tone, 'raw' : x[0]}\n",
        "  return songs\n",
        "\n",
        "songs = parse_songs()\n",
        "print(songs['1. 9 Ceea ce eşti mai cinstită']['x'])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1 -1  1 -1  1 -1  1  1  1  1 -1  1  5  1  1  1  1  1 -1 -1 -1 -1 -1  8\n",
            "  1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1  1  1 -1 -1 -2 -1  1  1  1  1  1  1\n",
            " -1  1 -1  1 -7  1  1  4  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -3\n",
            "  1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1  1  1  1  1  1 -1 -1 -3 -1 -1\n",
            " -1 -1  4  1  1 -1 -1 -1 -1 -1 -2  1  4 -1 -1  7  1  1  1 -1 -1 -1  1 -1\n",
            " -1 -1 -1  1  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -4  1  1  1  1\n",
            "  1  1  4  1  1  1  1 -1 -1 -1  3  1  1  1  1  1  1 -1 -1 -1 -1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1  1  1  1  1 -5  1  1  1  1  1  1  1  1  1 -1 -1 -1\n",
            " -1 -1 -1 -1 -1 -1 -1 -1  1  1  1  1  1  1 -1 -1 -3 -1 -1 -1 -1  1  1  1\n",
            "  1  1  1 -1 -1 -1 -1 -1 -1  1 -1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ATMdJH8GlQ-"
      },
      "source": [
        "import tensorflow.keras as keras\n",
        "kSequenceLength = 128\n",
        "kNumTones = 8\n",
        "\n",
        "def update(y):\n",
        "  return y - 1\n",
        "  # if y == 1:\n",
        "  #   return 0\n",
        "  # return 1\n",
        "\n",
        "def padarray(A, size):\n",
        "    t = size - len(A)\n",
        "    return np.pad(A, pad_width=(0, t), mode='constant')\n",
        "\n",
        "def generate_training_sequences(seq_len=kSequenceLength):\n",
        "  # load songs and map them to int\n",
        "  songs_ = parse_songs()\n",
        "\n",
        "  inputs, targets = [], []\n",
        "  for song in songs_:\n",
        "    x = songs_[song]['x']\n",
        "    y = songs_[song]['y']\n",
        "    y = update(y)\n",
        "    #x[np.insert(np.diff(x).astype(np.bool), 0, True)]\n",
        "    if len(x) < seq_len:\n",
        "      x = padarray(x, seq_len)\n",
        "    num_sequences = len(x) - seq_len + 1\n",
        "    for index in range(num_sequences):\n",
        "      inputs.append(np.asarray(x[index : index + seq_len]).reshape((seq_len, 1)))\n",
        "      targets.append(y)\n",
        "\n",
        "  # one-hot encode the sequences  \n",
        "  # inputs size: (# of sequences, sequence length, max(diff))\n",
        "  #inputs = keras.utils.to_categorical(inputs, num_classes=kOutputUnits)\n",
        "  inputs = np.asarray(inputs)\n",
        "  print(inputs.shape)\n",
        "  #n = len(inputs)\n",
        "  #inputs = np.reshape(inputs, (n, seq_len, 1))\n",
        "  # normalize input\n",
        "  #inputs = inputs / float(kOutputUnits)\n",
        "  \n",
        "  targets = keras.utils.to_categorical(targets, num_classes=kNumTones)\n",
        "  print(targets.shape)\n",
        "  print(f\"There are {len(inputs)} sequences.\")\n",
        "  return inputs, targets"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhu01Zj2HNKP",
        "outputId": "2e175a4b-b03b-415b-c555-f1f4eca48697"
      },
      "source": [
        "generate_training_sequences()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(53723, 128, 1)\n",
            "(53723, 8)\n",
            "There are 53723 sequences.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[ 1],\n",
              "         [-1],\n",
              "         [ 1],\n",
              "         ...,\n",
              "         [ 1],\n",
              "         [ 1],\n",
              "         [ 1]],\n",
              " \n",
              "        [[-1],\n",
              "         [ 1],\n",
              "         [-1],\n",
              "         ...,\n",
              "         [ 1],\n",
              "         [ 1],\n",
              "         [ 1]],\n",
              " \n",
              "        [[ 1],\n",
              "         [-1],\n",
              "         [ 1],\n",
              "         ...,\n",
              "         [ 1],\n",
              "         [ 1],\n",
              "         [ 1]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 1],\n",
              "         [ 1],\n",
              "         [-1],\n",
              "         ...,\n",
              "         [-1],\n",
              "         [ 1],\n",
              "         [ 1]],\n",
              " \n",
              "        [[ 1],\n",
              "         [-1],\n",
              "         [-1],\n",
              "         ...,\n",
              "         [ 1],\n",
              "         [ 1],\n",
              "         [-1]],\n",
              " \n",
              "        [[-1],\n",
              "         [-1],\n",
              "         [-1],\n",
              "         ...,\n",
              "         [ 1],\n",
              "         [-1],\n",
              "         [ 1]]]), array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 1.],\n",
              "        [0., 0., 0., ..., 0., 0., 1.],\n",
              "        [0., 0., 0., ..., 0., 0., 1.]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vixU6TGFKWo",
        "outputId": "7455684d-46f2-4448-8d9c-5073e0fa74eb"
      },
      "source": [
        "# load the dataset, returns train and test X and y elements\n",
        "def load_dataset():\n",
        "  # load all train\n",
        "  trainX, trainy = generate_training_sequences()\n",
        "  print(trainX.shape, trainy.shape)\n",
        "\n",
        "  # load all test\n",
        "  testX, testy = generate_training_sequences()\n",
        "  \n",
        "  # zero-offset class values\n",
        "  #trainy = trainy\n",
        "  #testy = testy\n",
        "  \n",
        "  # one hot encode y\n",
        "  print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
        "  return trainX, trainy, trainX, trainy\n",
        "\n",
        "load_dataset()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(53723, 128, 1)\n",
            "(53723, 8)\n",
            "There are 53723 sequences.\n",
            "(53723, 128, 1) (53723, 8)\n",
            "(53723, 128, 1)\n",
            "(53723, 8)\n",
            "There are 53723 sequences.\n",
            "(53723, 128, 1) (53723, 8) (53723, 128, 1) (53723, 8)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[ 1],\n",
              "         [-1],\n",
              "         [ 1],\n",
              "         ...,\n",
              "         [ 1],\n",
              "         [ 1],\n",
              "         [ 1]],\n",
              " \n",
              "        [[-1],\n",
              "         [ 1],\n",
              "         [-1],\n",
              "         ...,\n",
              "         [ 1],\n",
              "         [ 1],\n",
              "         [ 1]],\n",
              " \n",
              "        [[ 1],\n",
              "         [-1],\n",
              "         [ 1],\n",
              "         ...,\n",
              "         [ 1],\n",
              "         [ 1],\n",
              "         [ 1]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 1],\n",
              "         [ 1],\n",
              "         [-1],\n",
              "         ...,\n",
              "         [-1],\n",
              "         [ 1],\n",
              "         [ 1]],\n",
              " \n",
              "        [[ 1],\n",
              "         [-1],\n",
              "         [-1],\n",
              "         ...,\n",
              "         [ 1],\n",
              "         [ 1],\n",
              "         [-1]],\n",
              " \n",
              "        [[-1],\n",
              "         [-1],\n",
              "         [-1],\n",
              "         ...,\n",
              "         [ 1],\n",
              "         [-1],\n",
              "         [ 1]]]), array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 1.],\n",
              "        [0., 0., 0., ..., 0., 0., 1.],\n",
              "        [0., 0., 0., ..., 0., 0., 1.]], dtype=float32), array([[[ 1],\n",
              "         [-1],\n",
              "         [ 1],\n",
              "         ...,\n",
              "         [ 1],\n",
              "         [ 1],\n",
              "         [ 1]],\n",
              " \n",
              "        [[-1],\n",
              "         [ 1],\n",
              "         [-1],\n",
              "         ...,\n",
              "         [ 1],\n",
              "         [ 1],\n",
              "         [ 1]],\n",
              " \n",
              "        [[ 1],\n",
              "         [-1],\n",
              "         [ 1],\n",
              "         ...,\n",
              "         [ 1],\n",
              "         [ 1],\n",
              "         [ 1]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 1],\n",
              "         [ 1],\n",
              "         [-1],\n",
              "         ...,\n",
              "         [-1],\n",
              "         [ 1],\n",
              "         [ 1]],\n",
              " \n",
              "        [[ 1],\n",
              "         [-1],\n",
              "         [-1],\n",
              "         ...,\n",
              "         [ 1],\n",
              "         [ 1],\n",
              "         [-1]],\n",
              " \n",
              "        [[-1],\n",
              "         [-1],\n",
              "         [-1],\n",
              "         ...,\n",
              "         [ 1],\n",
              "         [-1],\n",
              "         [ 1]]]), array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 1.],\n",
              "        [0., 0., 0., ..., 0., 0., 1.],\n",
              "        [0., 0., 0., ..., 0., 0., 1.]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qr4RxxQ_FEwy",
        "outputId": "e292146f-cec8-41ec-880f-090baf841c06"
      },
      "source": [
        "kNumEpochs = 15\n",
        "kBatchSize = 64\n",
        "\n",
        "# fit and evaluate a model\n",
        "def evaluate_model(trainX, trainy, testX, testy, verbose=True):\n",
        "  n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
        "  print(n_timesteps, n_features, n_outputs)\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(100, input_shape=(n_timesteps, n_features)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(BatchNorm())\n",
        "  model.add(Dense(64, activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(BatchNorm())\n",
        "  model.add(Dense(n_outputs, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  model.summary()\n",
        "\n",
        "  filepath = model_dir + \"hypertone-weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "  checkpoint = ModelCheckpoint(\n",
        "      filepath,\n",
        "      monitor='loss',\n",
        "      verbose=0,\n",
        "      save_best_only=True,\n",
        "      mode='min'\n",
        "  )\n",
        "  callbacks = [checkpoint]\n",
        "\n",
        "  # fit network\n",
        "  model.fit(trainX, trainy, epochs=kNumEpochs, batch_size=kBatchSize, callbacks=callbacks, verbose=verbose)\n",
        "  # evaluate model\n",
        "  _, accuracy = model.evaluate(testX, testy, batch_size=kBatchSize, verbose=False)\n",
        "\n",
        "  # save the model\n",
        "  import time\n",
        "  model.save(model_file + '-' + str(int(time.time())) + '.hdf5')\n",
        "  return accuracy\n",
        "\n",
        "# summarize scores\n",
        "def summarize_results(scores):\n",
        "  print(scores)\n",
        "  m, s = mean(scores), std(scores)\n",
        "  print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
        "\n",
        "# run an experiment\n",
        "def run_experiment(repeats=1):\n",
        "  # load data\n",
        "  trainX, trainy, testX, testy = load_dataset()#'/content/drive/MyDrive/hypertone/preprocessing')\n",
        "  print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
        "  # repeat experiment\n",
        "  scores = list()\n",
        "  for r in range(repeats):\n",
        "    score = evaluate_model(trainX, trainy, testX, testy)\n",
        "    score = score * 100.0\n",
        "    print('>#%d: %.3f' % (r+1, score))\n",
        "    scores.append(score)\n",
        "  # summarize results\n",
        "  summarize_results(scores)\n",
        "\n",
        "# run the experiment\n",
        "run_experiment()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(53723, 128, 1)\n",
            "(53723, 8)\n",
            "There are 53723 sequences.\n",
            "(53723, 128, 1) (53723, 8)\n",
            "(53723, 128, 1)\n",
            "(53723, 8)\n",
            "There are 53723 sequences.\n",
            "(53723, 128, 1) (53723, 8) (53723, 128, 1) (53723, 8)\n",
            "(53723, 128, 1) (53723, 8) (53723, 128, 1) (53723, 8)\n",
            "128 1 8\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 100)               40800     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                6464      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 8)                 520       \n",
            "=================================================================\n",
            "Total params: 48,440\n",
            "Trainable params: 48,112\n",
            "Non-trainable params: 328\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "840/840 [==============================] - 30s 32ms/step - loss: 2.0651 - accuracy: 0.2492\n",
            "Epoch 2/15\n",
            "840/840 [==============================] - 27s 32ms/step - loss: 1.8355 - accuracy: 0.3364\n",
            "Epoch 3/15\n",
            "840/840 [==============================] - 27s 32ms/step - loss: 1.6614 - accuracy: 0.3853\n",
            "Epoch 4/15\n",
            "840/840 [==============================] - 27s 32ms/step - loss: 1.4190 - accuracy: 0.4694\n",
            "Epoch 5/15\n",
            "840/840 [==============================] - 27s 32ms/step - loss: 1.1265 - accuracy: 0.5887\n",
            "Epoch 6/15\n",
            "840/840 [==============================] - 26s 31ms/step - loss: 0.8942 - accuracy: 0.6817\n",
            "Epoch 7/15\n",
            "840/840 [==============================] - 26s 31ms/step - loss: 0.6055 - accuracy: 0.7950\n",
            "Epoch 8/15\n",
            "840/840 [==============================] - 26s 31ms/step - loss: 0.4491 - accuracy: 0.8562\n",
            "Epoch 9/15\n",
            "840/840 [==============================] - 26s 31ms/step - loss: 0.3565 - accuracy: 0.8905\n",
            "Epoch 10/15\n",
            "840/840 [==============================] - 26s 31ms/step - loss: 0.2682 - accuracy: 0.9190\n",
            "Epoch 11/15\n",
            "840/840 [==============================] - 26s 31ms/step - loss: 0.2194 - accuracy: 0.9362\n",
            "Epoch 12/15\n",
            "840/840 [==============================] - 26s 31ms/step - loss: 0.1908 - accuracy: 0.9443\n",
            "Epoch 13/15\n",
            "840/840 [==============================] - 26s 31ms/step - loss: 0.1408 - accuracy: 0.9596\n",
            "Epoch 14/15\n",
            "840/840 [==============================] - 26s 31ms/step - loss: 0.1513 - accuracy: 0.9566\n",
            "Epoch 15/15\n",
            "840/840 [==============================] - 26s 31ms/step - loss: 0.1787 - accuracy: 0.9515\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-ccfd53ac32ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# run the experiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-ccfd53ac32ad>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(repeats)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>#%d: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-ccfd53ac32ad>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(trainX, trainy, testX, testy, verbose)\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0;31m# save the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_file' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccMBaQ0RFQod",
        "outputId": "4e10d852-940f-4558-8137-7b9aef443d52"
      },
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import IPython.display as ipd\n",
        "\n",
        "# TODO: this should come into a separate script!\n",
        "kBinsPerOctave = 24\n",
        "\n",
        "# Corresponds to a jump from Pa -> Ga\n",
        "kJump = int(4/3 * kBinsPerOctave)\n",
        "\n",
        "fmin = librosa.midi_to_hz(36) # C2 (Ison)\n",
        "fmax = librosa.midi_to_hz(84) # C6 (highest note ever seen in byzantine sheets: A5#)\n",
        "print(fmin)\n",
        "print(fmax)\n",
        "\n",
        "import math\n",
        "\n",
        "def find_bin(f):\n",
        "# Find which bin `f` fits into.\n",
        "# The bins are geometrically distributed.\n",
        "# Formula: 2**(i/`kBinsPerOctave`) * fmin\n",
        "# Source: https://en.wikipedia.org/wiki/Constant-Q_transform\n",
        "  return int(round(math.log2(f / fmin) * kBinsPerOctave)) if not math.isnan(f) else f\n",
        "\n",
        "def normalize_diffs(bins):\n",
        "  pitch_diff = []\n",
        "  last_index_non_nan = None\n",
        "  for index, elem in enumerate(bins):\n",
        "    # First position?\n",
        "    if index == 0:\n",
        "      continue\n",
        "    # NaN?\n",
        "    if math.isnan(elem):\n",
        "      continue\n",
        "    # No prev elem which is not NaN?\n",
        "    if last_index_non_nan is None:\n",
        "      last_index_non_nan = index\n",
        "      continue\n",
        "    diff = bins[index] - bins[last_index_non_nan]\n",
        "\n",
        "    if abs(diff) > kJump:\n",
        "      last_index_non_nan = index\n",
        "      continue\n",
        "\n",
        "    # isPositive = diff > 0\n",
        "    # while abs(diff) > kJump and diff < 0:\n",
        "    #   # `bins[last_index_non_nan]` >= `elem`.\n",
        "    #   bins[index] += kBinsPerOctave\n",
        "    #   diff = bins[index] - bins[last_index_non_nan]\n",
        "      \n",
        "    # while abs(diff) > kJump and diff > 0:\n",
        "    #   # `bins[last_index_non_nan]` <= `elem`.\n",
        "    #   pyin_bins[last_index_non_nan] += kBinsPerOctave\n",
        "    #   diff = bins[index] - bins[last_index_non_nan]\n",
        "    \n",
        "    # Update\n",
        "    last_index_non_nan = index\n",
        "    pitch_diff.append(diff)\n",
        "  return pitch_diff\n",
        "\n",
        "from scipy.signal import savgol_filter\n",
        "\n",
        "def solve_audio(filepath_, tone_=0):\n",
        "  y_, sr_ = librosa.load(filepath_)\n",
        "  f0_, voiced_flag_, voiced_probs_ = librosa.pyin(y_, fmin=fmin, fmax=fmax)\n",
        "\n",
        "  # Number of seconds\n",
        "  num_seconds_ = len(y_) / sr_\n",
        "\n",
        "  # How many pyin samples / second\n",
        "  samples_per_second_ = (len(f0_) / num_seconds_)\n",
        "  \n",
        "  # Compute the window length\n",
        "  window_length_ = int(samples_per_second_ / 3)\n",
        "  if window_length_ % 2 == 0:\n",
        "    window_length_ += 1\n",
        "\n",
        "  print(f\"samples_per_second={samples_per_second_}, window_length={window_length_}\")\n",
        "\n",
        "  # Filter\n",
        "  num_skips_ = int(samples_per_second_ * 5)\n",
        "  yhat_ = savgol_filter(f0_[num_skips_:], window_length_, 1)\n",
        "\n",
        "  # And determine the bins\n",
        "  filtered_bins_ = list(map(find_bin, yhat_))\n",
        "  return [filtered_bins_, normalize_diffs(filtered_bins_), tone_]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65.40639132514966\n",
            "1046.5022612023945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F3pwkU3EIhI"
      },
      "source": [
        "class HyperTone:\n",
        "  def __init__(self, model_path_):\n",
        "    self.model = keras.models.load_model(model_path_)\n",
        "  \n",
        "  def extract_tones(self, filepath_, seq_len_=kSequenceLength):\n",
        "    ret = solve_audio(filepath_)\n",
        "    x = np.asarray(ret[1])\n",
        "    x = x[x != 0]\n",
        "\n",
        "    if len(x) < seq_len_:\n",
        "      x = padarray(x, seq_len_)\n",
        "    num_sequences = len(x) - seq_len_ + 1\n",
        "    seeds = []\n",
        "    for index in range(num_sequences):\n",
        "      seeds.append(np.asarray(x[index : index + seq_len_]).reshape((seq_len_, 1)))\n",
        "    output = self.model.predict(np.asarray(seeds))\n",
        "\n",
        "    y = []\n",
        "    for index, elem in enumerate(output):\n",
        "      y.append(1 + self.sample(elem))\n",
        "    return y\n",
        "    #   # make a prediction\n",
        "    #   #output = self.model.predict(seed)\n",
        "    #   output = self.model.predict(seed)[0]\n",
        "    #   #classes_x=np.argmax(predict_x,axis=1)\n",
        "    #   #print(f\"predict_x={predict_x}\")\n",
        "    #   #print(f\"classes_x={classes_x}\")\n",
        "    #   y.append(output)\n",
        "    #   #print(pr\n",
        "\n",
        "    #   #print(probabilities)\n",
        "    #   #index = self.sample(probabilities)\n",
        "    #   #y.append(1 + index)              \n",
        "    # return y\n",
        "\n",
        "  def sample(self, probabilites, temperature=0.1):\n",
        "    \"\"\"Samples an index from a probability array reapplying softmax using temperature\n",
        "\n",
        "    :param predictions (nd.array): Array containing probabilities for each of the possible outputs.\n",
        "    :param temperature (float): Float in interval [0, 1]. Numbers closer to 0 make the model more deterministic.\n",
        "        A number closer to 1 makes the generation more unpredictable.\n",
        "\n",
        "    :return index (int): Selected output symbol\n",
        "    \"\"\"\n",
        "    predictions = np.log(probabilites) / temperature\n",
        "    probabilites = np.exp(predictions) / np.sum(np.exp(predictions))\n",
        "\n",
        "    choices = range(len(probabilites)) # [0, 1, 2, 3]\n",
        "    index = np.random.choice(choices, p=probabilites)\n",
        "\n",
        "    return index"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_Pay1SeHiM8",
        "outputId": "d7282fd4-db03-4123-8938-f79cdc8239e1"
      },
      "source": [
        "test_filename = '/content/drive/MyDrive/psaltica_nepsis_ch/utrenia_8_glasuri_ierom_macarie/utrenia-glas4-macarie/Inregistrari/4. 15 Preabinecuvântată eşti.m4a'\n",
        "ht = HyperTone(model_dir + 'hypertone-weights-improvement-15-0.1191.hdf5')\n",
        "print(ht.extract_tones(test_filename))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "samples_per_second=43.081287523756046, window_length=15\n",
            "[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n"
          ]
        }
      ]
    }
  ]
}